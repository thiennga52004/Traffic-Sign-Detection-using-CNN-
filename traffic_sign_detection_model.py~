# -*- coding: utf-8 -*-
"""Traffic_Sign_Detection_Model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AUhpVcddzRpENV8IFsL8xZjWSK1c5tnB
"""

import numpy as np #hỗ trợ làm việc với dữ liệu dạng mảng
import matplotlib.pyplot as plt #vẽ biểu đồ
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential #mô hình mạng Neural
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout #Conv2D: dùng để phát hiện đặc trưng của ảnh, MaxPooling2D: dùng để giảm kích thước của ảnh, Flatten: Chuyển dữ liệu ma trận thành vector để đưa vào Dense, Dense: Lớp kết nối đầy đủ để học các đặc trưng phức tạp, Dropout: chống overfitting
from tensorflow.keras.optimizers import Adam #Tối ưu thuật toán giúp mô hình học tập nhanh hơn và chính xác hơn
from tensorflow.keras.utils import to_categorical
import cv2
from sklearn.model_selection import train_test_split #chia dữ liệu ra các tập
import pickle
import os
import pandas as pd #đọc file labels.csv
import random
from tensorflow.keras.preprocessing.image import ImageDataGenerator


dataset_path="/content/drive/MyDrive/NienLuan/myData"
labels_path = "/content/drive/MyDrive/NienLuan/labels.csv"
batch_sizevalue=32 # để 32 ảnh vào trong 1 process
epochs_val=10
imageDimensions=(32,32,3) #resize ảnh vào 1 định dạng 32x32 3 là RGB
testRatio=0.2 # lấy 20% trong số ảnh để test
validationRatio=0.2 # lấy 20% trong số ảnh còn lại để xác thực

# Import ảnh
count=0
images=[]
classNum=[]
myList=os.listdir(dataset_path)
print("Total Classes Detected:",len(myList))
noOfClasses=len(myList)
print("Importing Classes.....")
for i in range(0,len(myList)):
    myImgList=os.listdir(dataset_path+"/"+str(count))
    for j in myImgList:
        img=cv2.imread(dataset_path+"/"+str(i)+"/"+j)
        images.append(img)
        classNum.append(count)
    print(count, end=" ")
    count+=1
print(" ")
images=np.array(images)
classNum=np.array(classNum)

# Tách dữ liệu
train1,test1, train2, test2 = train_test_split(images, classNum, test_size=testRatio)
train1, valid1, train2, valid2 = train_test_split(train1, train2, test_size=validationRatio)
# train1 là mảng hình để train
# train2 là class tương ứng

# Kiểm tra số lượng ảnh có khớp với tên của từng dataset
print("Data shapes")
print("Train : ", end="")
print(train1.shape, train2.shape)
print("Validation : ", end="")
print(valid1.shape, valid2.shape)
print("Test : ", end="")
print(test1.shape,test2.shape)

#Đọc file csv
data=pd.read_csv(labels_path)
print("data shape", data.shape, type(data))

# Load vài ảnh của các classes
samplesNum=[]
cols=5
classesNum=noOfClasses
fig, axs=plt.subplots(nrows=classesNum, ncols=cols, figsize=(5,100)) #plt.subplots sẽ tạo biểu đồ với kích thước 5x100
fig.tight_layout #đảm bảo ảnh không bị chồng lên nhau
for i in range(cols): #duyệt 5 ảnh của mỗi class
  for j, row in data.iterrows(): #lặp từng class trong data
    selected=train1[train2==j] #lọc các ảnh thuộc lớp thứ j
    axs[j][i].imshow(selected[random.randint(0, len(selected)-1), :, :], cmap=plt.get_cmap("gray")) #random sẽ chọn ngẫu nhiên ảnh trong class và hiện ra vị trí của ảnh trong biểu đồ
    axs[j][i].axis("off") #không hiển thị trục tọa độ
    if i==2:
      axs[j][i].set_title(str(j)+"-"+row["Name"])
      samplesNum.append(len(selected))

# Tạo biểu đồ cột biểu diễn số lượng ảnh của từng loại
print(samplesNum)
plt.figure(figsize=(12,4))
plt.bar(range(0, classesNum), samplesNum)
plt.title("Distribution of the training dataset")
plt.xlabel("Class number")
plt.ylabel("Number of images")
plt.show()

def grayscale(img):
    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    return img
def equalize(img):
    img =cv2.equalizeHist(img)
    return img
def preprocessing(img):
    img = grayscale(img)
    img = equalize(img)
    img = img/255
    return img

train1=np.array(list(map(preprocessing,train1)))
valid1=np.array(list(map(preprocessing,valid1)))
test1=np.array(list(map(preprocessing,test1)))

#Chuyển định dạng để CNN train
train1=train1.reshape(train1.shape[0], train1.shape[1], train1.shape[2], 1)
valid1=valid1.reshape(valid1.shape[0], valid1.shape[1], valid1.shape[2], 1)
test1=test1.reshape(test1.shape[0], test1.shape[1], test1.shape[2], 1)

dataGen = ImageDataGenerator(width_shift_range=0.1,
                             height_shift_range=0.1,
                             zoom_range=0.2,
                             shear_range=0.1,
                             rotation_range=10)
dataGen.fit(train1)
batches=dataGen.flow(train1, train2, batch_size=20)
batch1, batch2 = next(batches)

fig,axs=plt.subplots(1,15,figsize=(20,5))
fig.tight_layout()
for i in range(15):
  axs[i].imshow(batch1[i].reshape(imageDimensions[0],imageDimensions[1]))
  axs[i].axis('off')
plt.show()

train2=to_categorical(train2, noOfClasses)
valid2=to_categorical(valid2, noOfClasses)
test2=to_categorical(test2, noOfClasses)

#mô hình cnn
def cnnModel():
  sizeOfFilter=(3,3)
  sizeOfPool=(2,2)
  noOfNodes=256
  model=Sequential()
  # Layer 1
  model.add((Conv2D(32, sizeOfFilter, input_shape=(imageDimensions[0], imageDimensions[1], 1), activation='relu')))
  model.add((Conv2D(32, sizeOfFilter, activation='relu')))
  model.add(MaxPooling2D(pool_size=sizeOfPool))
  model.add(Dropout(0.25))
  # Layer 2
  model.add((Conv2D(64, sizeOfFilter, activation='relu')))
  model.add((Conv2D(64, sizeOfFilter, activation='relu')))
  model.add(MaxPooling2D(pool_size=sizeOfPool))
  model.add(Dropout(0.25))
  model.add(Flatten())
  model.add(Dense(noOfNodes, activation='relu'))
  model.add(Dropout(0.5))
  model.add(Dense(noOfClasses, activation='softmax'))
  model.compile(Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])
  return model

#train model
model=cnnModel()
print(model.summary())
my_callbacks=[
    tf.keras.callbacks.EarlyStopping(patience=2),
    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),
    tf.keras.callbacks.TensorBoard(log_dir='./logs'),
]
history = model.fit(dataGen.flow(train1, train2, batch_size=batch_sizevalue),
                    epochs=epochs_val,
                    validation_data=(valid1, valid2),
                    shuffle=True)

#show plot
plt.figure(1)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['training', 'validation'])
plt.title('loss')
plt.xlabel('epoch')
plt.figure(2)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.legend(['training', 'validation'])
plt.title('Accuracy')
plt.xlabel('epoch')
plt.show()
score=model.evaluate(test1, test2, verbose=0)
print('Test Score:', score[0])
print('Test Accuracy:', score[1])

model.save("traffic_sign_model.h5")
print("Model saved succesfully")